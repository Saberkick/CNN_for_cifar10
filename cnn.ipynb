{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d345d923",
   "metadata": {},
   "source": [
    "## å¯¼å…¥æ‰€éœ€åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecda643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713acae",
   "metadata": {},
   "source": [
    "## ä»£ç "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d162360",
   "metadata": {},
   "source": [
    "- å‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. æ•°æ®å‡†å¤‡ (åŒ…å«å½’ä¸€åŒ–ä¼˜åŒ–)\n",
    "# ---------------------------------------------------------\n",
    "# CIFAR-10 æ ‡å‡†å‡å€¼å’Œæ ‡å‡†å·®\n",
    "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR_STD = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD) # å¯ç”¨å½’ä¸€åŒ–\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
    "])\n",
    "\n",
    "# æ•°æ®é›†åŠ è½½\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c3c49",
   "metadata": {},
   "source": [
    "- å®šä¹‰model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 2. å®šä¹‰ LightningModule\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "class LitConvNet(L.LightningModule):\n",
    "    def __init__(self, num_classes=10, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # 1. å¢å¼ºå·ç§¯å±‚ï¼šå¢åŠ é€šé“æ•°ï¼ˆä»16/32 æå‡è‡³ 64/128/256ï¼‰\n",
    "        # é€šé“æ•°è¶Šå¤šï¼Œæ¨¡å‹â€œè„‘å®¹é‡â€è¶Šå¤§ï¼Œèƒ½è®°ä½çš„ç‰¹å¾è¶Šä¸°å¯Œ\n",
    "        self.features = nn.Sequential(\n",
    "            # ç¬¬ä¸€å—ï¼šè¾“å…¥ 3x32x32 -> è¾“å‡º 64x16x16\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2), # Dropout\n",
    "\n",
    "            # ç¬¬äºŒå—ï¼šè¾“å‡º 128x8x8\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.3),\n",
    "\n",
    "            # ç¬¬ä¸‰å—ï¼šè¾“å‡º 256x4x4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.4)\n",
    "        )\n",
    "\n",
    "        # 2. å¢å¼ºå…¨è¿æ¥å±‚ (Classifier)\n",
    "        # 4*4*256 = 4096\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4 * 4 * 256, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.5), # é«˜æ¯”ä¾‹ Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1) # å±•å¹³\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y, label_smoothing=0.1) # å¼•å…¥æ ‡ç­¾å¹³æ»‘\n",
    "\n",
    "        acc = (logits.argmax(1) == y).float().mean()\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # ä½¿ç”¨ AdamW é…åˆæ›´å¼ºçš„å­¦ä¹ ç‡ç­–ç•¥\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=0.01)\n",
    "\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.hparams.lr*10,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "            pct_start=0.1,\n",
    "            div_factor=10,\n",
    "            final_div_factor=100\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9db4ad",
   "metadata": {},
   "source": [
    "- è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ce5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/usr/local/miniconda3/lib/python3.13/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type       </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ features   â”‚ Sequential â”‚  556 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ classifier â”‚ Sequential â”‚  4.7 M â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType      \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ features   â”‚ Sequential â”‚  556 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ classifier â”‚ Sequential â”‚  4.7 M â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 5.3 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 5.3 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 21                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 32                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 5.3 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 5.3 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 21                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 32                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96f416c43e44b20bba3c8a729ab7cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3. è®­ç»ƒå™¨è®¾ç½®ä¸å¯åŠ¨\n",
    "# ---------------------------------------------------------\n",
    "# å®ä¾‹åŒ–æ¨¡å‹\n",
    "model = LitConvNet(num_classes=10, lr=0.001)\n",
    "model = torch.compile(model)\n",
    "\n",
    "# å®šä¹‰ Trainer\n",
    "# Lightning ä¼šè‡ªåŠ¨å¤„ç†è®¾å¤‡æ˜ å°„\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"auto\",   # å¦‚æœæœ‰ GPU åˆ™ä½¿ç”¨\n",
    "    devices=1,           # ä½¿ç”¨ 1 å—å¡\n",
    "    precision=\"bf16-mixed\", # å¯é€‰ï¼šå¼€å¯æ··åˆç²¾åº¦è®­ç»ƒï¼Œé€Ÿåº¦æ›´å¿«ï¼Œæ˜¾å­˜å ç”¨æ›´ä½\n",
    "    logger=True             # Ensure tensorboard is installed first\n",
    ")\n",
    "\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d833f",
   "metadata": {},
   "source": [
    "## æ¨¡å‹æµ‹è¯•ä¸ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa15df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.57%\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. æµ‹è¯•æ¨¡å‹å‡†ç¡®ç‡\n",
    "# ---------------------------------------------------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(model.device)\n",
    "            labels = labels.to(model.device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eade781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ä¿å­˜æ¨¡å‹\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
